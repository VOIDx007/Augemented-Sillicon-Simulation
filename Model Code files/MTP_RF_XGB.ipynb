{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#Check for TPU connection\n",
        "import os\n",
        "  \n",
        "if 'COLAB_TPU_ADDR' not in os.environ:\n",
        "  print('Not connected to TPU')\n",
        "else:\n",
        "  print(\"Connected to TPU\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5shxvcvg02u",
        "outputId": "3052360b-ce0d-401d-c0e0-3df31851a861"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not connected to TPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Check for GPU connection\n",
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "metadata": {
        "id": "NxyZ61GNjAHH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "cbd1dca0-bfb4-4f15-fc42-4186f8384549"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "''"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IzUgakHwBcp5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "import numpy as np\n",
        "from numpy import inf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir images"
      ],
      "metadata": {
        "id": "h8gkoYDkCyZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_doped = pd.read_csv('Real_Train_cleaned.csv')\n",
        "for i in range(1, 321):\n",
        "  df_doped.iloc[:,i] = (df_doped.iloc[:,i] - df_doped.iloc[:,i].min()) / (df_doped.iloc[:,i].max() - df_doped.iloc[:,i].min())\n",
        "df_doped.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "id": "4IB0oG0EC7Me",
        "outputId": "c3ab9ad6-7f10-4df6-c9c5-f77713784655"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   applied bias  DOPING PROFILE  DOPING PROFILE.1  DOPING PROFILE.2  \\\n",
              "0           0.0             0.0               0.0               0.0   \n",
              "1           0.0             0.0               0.0               0.0   \n",
              "2           0.0             0.0               0.0               0.0   \n",
              "3           0.0             0.0               0.0               0.0   \n",
              "4           0.0             0.0               0.0               0.0   \n",
              "5           0.0             0.0               0.0               0.0   \n",
              "6           0.0             0.0               0.0               0.0   \n",
              "7           0.0             0.0               0.0               0.0   \n",
              "8           0.0             0.0               0.0               0.0   \n",
              "9           0.0             0.0               0.0               0.0   \n",
              "\n",
              "   DOPING PROFILE.3  DOPING PROFILE.4  DOPING PROFILE.5  DOPING PROFILE.6  \\\n",
              "0               0.0               0.0               0.0               0.0   \n",
              "1               0.0               0.0               0.0               0.0   \n",
              "2               0.0               0.0               0.0               0.0   \n",
              "3               0.0               0.0               0.0               0.0   \n",
              "4               0.0               0.0               0.0               0.0   \n",
              "5               0.0               0.0               0.0               0.0   \n",
              "6               0.0               0.0               0.0               0.0   \n",
              "7               0.0               0.0               0.0               0.0   \n",
              "8               0.0               0.0               0.0               0.0   \n",
              "9               0.0               0.0               0.0               0.0   \n",
              "\n",
              "   DOPING PROFILE.7  DOPING PROFILE.8  ...  FB-PP.310  FB-PP.311  FB-PP.312  \\\n",
              "0               0.0               0.0  ...   0.039862   0.039863   0.039864   \n",
              "1               0.0               0.0  ...   0.039834   0.039836   0.039838   \n",
              "2               0.0               0.0  ...   0.039801   0.039804   0.039807   \n",
              "3               0.0               0.0  ...   0.039851   0.039853   0.039854   \n",
              "4               0.0               0.0  ...   0.039817   0.039820   0.039823   \n",
              "5               0.0               0.0  ...   0.039702   0.039706   0.039710   \n",
              "6               0.0               0.0  ...   0.039680   0.039685   0.039689   \n",
              "7               0.0               0.0  ...   0.039798   0.039801   0.039804   \n",
              "8               0.0               0.0  ...   0.039744   0.039749   0.039754   \n",
              "9               0.0               0.0  ...   0.039850   0.039852   0.039853   \n",
              "\n",
              "   FB-PP.313  FB-PP.314  FB-PP.315  FB-PP.316  FB-PP.317  FB-PP.318  FB-PP.319  \n",
              "0   0.039865   0.039866   0.039866   0.039867   0.039868   0.039868   0.039868  \n",
              "1   0.039840   0.039841   0.039843   0.039844   0.039845   0.039847   0.039847  \n",
              "2   0.039810   0.039813   0.039815   0.039817   0.039819   0.039821   0.039821  \n",
              "3   0.039855   0.039857   0.039858   0.039859   0.039859   0.039860   0.039860  \n",
              "4   0.039825   0.039827   0.039829   0.039831   0.039832   0.039834   0.039834  \n",
              "5   0.039714   0.039717   0.039720   0.039723   0.039725   0.039728   0.039728  \n",
              "6   0.039694   0.039698   0.039701   0.039705   0.039708   0.039711   0.039711  \n",
              "7   0.039807   0.039810   0.039813   0.039815   0.039817   0.039819   0.039819  \n",
              "8   0.039759   0.039763   0.039767   0.039771   0.039774   0.039777   0.039777  \n",
              "9   0.039854   0.039855   0.039857   0.039858   0.039859   0.039859   0.039859  \n",
              "\n",
              "[10 rows x 1281 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-284c2fb6-0768-4fa9-8ceb-42171c2c1663\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>applied bias</th>\n",
              "      <th>DOPING PROFILE</th>\n",
              "      <th>DOPING PROFILE.1</th>\n",
              "      <th>DOPING PROFILE.2</th>\n",
              "      <th>DOPING PROFILE.3</th>\n",
              "      <th>DOPING PROFILE.4</th>\n",
              "      <th>DOPING PROFILE.5</th>\n",
              "      <th>DOPING PROFILE.6</th>\n",
              "      <th>DOPING PROFILE.7</th>\n",
              "      <th>DOPING PROFILE.8</th>\n",
              "      <th>...</th>\n",
              "      <th>FB-PP.310</th>\n",
              "      <th>FB-PP.311</th>\n",
              "      <th>FB-PP.312</th>\n",
              "      <th>FB-PP.313</th>\n",
              "      <th>FB-PP.314</th>\n",
              "      <th>FB-PP.315</th>\n",
              "      <th>FB-PP.316</th>\n",
              "      <th>FB-PP.317</th>\n",
              "      <th>FB-PP.318</th>\n",
              "      <th>FB-PP.319</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.039862</td>\n",
              "      <td>0.039863</td>\n",
              "      <td>0.039864</td>\n",
              "      <td>0.039865</td>\n",
              "      <td>0.039866</td>\n",
              "      <td>0.039866</td>\n",
              "      <td>0.039867</td>\n",
              "      <td>0.039868</td>\n",
              "      <td>0.039868</td>\n",
              "      <td>0.039868</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.039834</td>\n",
              "      <td>0.039836</td>\n",
              "      <td>0.039838</td>\n",
              "      <td>0.039840</td>\n",
              "      <td>0.039841</td>\n",
              "      <td>0.039843</td>\n",
              "      <td>0.039844</td>\n",
              "      <td>0.039845</td>\n",
              "      <td>0.039847</td>\n",
              "      <td>0.039847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.039801</td>\n",
              "      <td>0.039804</td>\n",
              "      <td>0.039807</td>\n",
              "      <td>0.039810</td>\n",
              "      <td>0.039813</td>\n",
              "      <td>0.039815</td>\n",
              "      <td>0.039817</td>\n",
              "      <td>0.039819</td>\n",
              "      <td>0.039821</td>\n",
              "      <td>0.039821</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.039851</td>\n",
              "      <td>0.039853</td>\n",
              "      <td>0.039854</td>\n",
              "      <td>0.039855</td>\n",
              "      <td>0.039857</td>\n",
              "      <td>0.039858</td>\n",
              "      <td>0.039859</td>\n",
              "      <td>0.039859</td>\n",
              "      <td>0.039860</td>\n",
              "      <td>0.039860</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.039817</td>\n",
              "      <td>0.039820</td>\n",
              "      <td>0.039823</td>\n",
              "      <td>0.039825</td>\n",
              "      <td>0.039827</td>\n",
              "      <td>0.039829</td>\n",
              "      <td>0.039831</td>\n",
              "      <td>0.039832</td>\n",
              "      <td>0.039834</td>\n",
              "      <td>0.039834</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.039702</td>\n",
              "      <td>0.039706</td>\n",
              "      <td>0.039710</td>\n",
              "      <td>0.039714</td>\n",
              "      <td>0.039717</td>\n",
              "      <td>0.039720</td>\n",
              "      <td>0.039723</td>\n",
              "      <td>0.039725</td>\n",
              "      <td>0.039728</td>\n",
              "      <td>0.039728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.039680</td>\n",
              "      <td>0.039685</td>\n",
              "      <td>0.039689</td>\n",
              "      <td>0.039694</td>\n",
              "      <td>0.039698</td>\n",
              "      <td>0.039701</td>\n",
              "      <td>0.039705</td>\n",
              "      <td>0.039708</td>\n",
              "      <td>0.039711</td>\n",
              "      <td>0.039711</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.039798</td>\n",
              "      <td>0.039801</td>\n",
              "      <td>0.039804</td>\n",
              "      <td>0.039807</td>\n",
              "      <td>0.039810</td>\n",
              "      <td>0.039813</td>\n",
              "      <td>0.039815</td>\n",
              "      <td>0.039817</td>\n",
              "      <td>0.039819</td>\n",
              "      <td>0.039819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.039744</td>\n",
              "      <td>0.039749</td>\n",
              "      <td>0.039754</td>\n",
              "      <td>0.039759</td>\n",
              "      <td>0.039763</td>\n",
              "      <td>0.039767</td>\n",
              "      <td>0.039771</td>\n",
              "      <td>0.039774</td>\n",
              "      <td>0.039777</td>\n",
              "      <td>0.039777</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.039850</td>\n",
              "      <td>0.039852</td>\n",
              "      <td>0.039853</td>\n",
              "      <td>0.039854</td>\n",
              "      <td>0.039855</td>\n",
              "      <td>0.039857</td>\n",
              "      <td>0.039858</td>\n",
              "      <td>0.039859</td>\n",
              "      <td>0.039859</td>\n",
              "      <td>0.039859</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 1281 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-284c2fb6-0768-4fa9-8ceb-42171c2c1663')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-284c2fb6-0768-4fa9-8ceb-42171c2c1663 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-284c2fb6-0768-4fa9-8ceb-42171c2c1663');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = df_doped.iloc[:,0:641].values\n",
        "y = df_doped.iloc[:,961:1281].values\n",
        "x.shape"
      ],
      "metadata": {
        "id": "2LgvD9WLDMtY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "195737c1-393b-4f30-b110-983e1360dade"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(962, 641)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,1):\n",
        "  bias = x[:,i]\n",
        "\n",
        "  bias_inv = np.reciprocal(bias)\n",
        "  bias_inv[bias_inv == inf] = 0\n",
        "\n",
        "  bias_0_5 = np.power(bias,0.5)\n",
        "  bias_inv_0_5 = np.power(bias_inv,0.5)\n",
        "\n",
        "  bias_2 = np.power(bias,2)\n",
        "  bias_inv_2 = np.power(bias_inv,2)\n",
        "\n",
        "  bias_3 = np.power(bias,3)\n",
        "  bias_inv_3 = np.power(bias_inv,3)\n",
        "\n",
        "  bias_log = np.log(bias)\n",
        "  bias_log_inv = np.reciprocal(bias_log)\n",
        "  bias_log[bias_log==-inf] = 0\n",
        "  bias_log[bias_log==inf] = 0 \n",
        "  bias_log_inv[bias_log==-inf] = 0\n",
        "  bias_log_inv[bias_log==inf] = 0 \n",
        "\n",
        "  bias_neg = bias*(-1)\n",
        "  bias_exp = np.exp(bias)\n",
        "  bias_neg_exp = np.exp(bias_neg)\n",
        "\n",
        "  b = bias_inv.reshape(-1,1)\n",
        "  x = np.append(x,b,axis=1)\n",
        "\n",
        "  b = bias_0_5.reshape(-1,1)\n",
        "  x = np.append(x,b,axis=1)\n",
        "\n",
        "\n",
        "  b = bias_inv_0_5.reshape(-1,1)\n",
        "  x = np.append(x,b,axis=1)\n",
        "\n",
        "  b = bias_2.reshape(-1,1)\n",
        "  x = np.append(x,b,axis=1)\n",
        "\n",
        "  b = bias_inv_2.reshape(-1,1)\n",
        "  x = np.append(x,b,axis=1)\n",
        "\n",
        "  b = bias_3.reshape(-1,1)\n",
        "  x = np.append(x,b,axis=1)\n",
        "\n",
        "  b = bias_inv_3.reshape(-1,1)\n",
        "  x = np.append(x,b,axis=1)\n",
        "\n",
        "  b = bias_log.reshape(-1,1)\n",
        "  x = np.append(x,b,axis=1)\n",
        "\n",
        "  b = bias_log_inv.reshape(-1,1)\n",
        "  x = np.append(x,b,axis=1)\n",
        "\n",
        "  b = bias_exp.reshape(-1,1)\n",
        "  x = np.append(x,b,axis=1)\n",
        "\n",
        "  b = bias_neg_exp.reshape(-1,1)\n",
        "  x = np.append(x,b,axis=1)\n",
        "\n",
        "x.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cwj2G2_L5dtJ",
        "outputId": "0b653427-6a04-45fa-a9a5-d8fdddc851de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-68d81f4c5b31>:4: RuntimeWarning: divide by zero encountered in reciprocal\n",
            "  bias_inv = np.reciprocal(bias)\n",
            "<ipython-input-4-68d81f4c5b31>:16: RuntimeWarning: divide by zero encountered in log\n",
            "  bias_log = np.log(bias)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(962, 652)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.where(np.isinf(x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tD-BExY34rDl",
        "outputId": "a4d2665d-ddb1-4915-c52d-cb8b9663527a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([], dtype=int64), array([], dtype=int64))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.where(np.isnan(x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlNgaMs1_u2k",
        "outputId": "a7acae7b-0d1c-4981-ae70-cc25c10a0e75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([], dtype=int64), array([], dtype=int64))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.where(np.isnan(y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H29gLeAHKv-7",
        "outputId": "120b5232-34bb-40c1-9f2d-8e10b60fcb80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([], dtype=int64), array([], dtype=int64))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[x==inf] = 0"
      ],
      "metadata": {
        "id": "Weum5jd27RO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.nan_to_num(x)"
      ],
      "metadata": {
        "id": "0sDLUiUY_-dG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NN1jrKvUBJp4",
        "outputId": "26f4246d-ccf2-427e-e315-513b6c14fc72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(962, 320)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#XGBoost\n",
        "#my_model_1 = MultiOutputRegressor(XGBRegressor(learning_rate=0.1, n_estimators=500, nthread = -1, subsample=0.6, tree_method=\"hist\", grow_policy=\"lossguide\"))\n",
        "my_model_1 = MultiOutputRegressor(XGBRegressor(learning_rate=0.1, n_estimators=500, nthread = -1, subsample=0.6, tree_method=\"exact\"))\n",
        "my_model_1.fit(x,y)"
      ],
      "metadata": {
        "id": "y4Q9NhJcD_G-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        },
        "outputId": "8dc92dac-3e41-4da8-82d6-e6b8873d6716"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultiOutputRegressor(estimator=XGBRegressor(base_score=None, booster=None,\n",
              "                                            callbacks=None,\n",
              "                                            colsample_bylevel=None,\n",
              "                                            colsample_bynode=None,\n",
              "                                            colsample_bytree=None,\n",
              "                                            early_stopping_rounds=None,\n",
              "                                            enable_categorical=False,\n",
              "                                            eval_metric=None,\n",
              "                                            feature_types=None, gamma=None,\n",
              "                                            gpu_id=None, grow_policy=None,\n",
              "                                            importance_type=None,\n",
              "                                            interaction_constraints=None,\n",
              "                                            learning_rate=0.1, max_bin=None,\n",
              "                                            max_cat_threshold=None,\n",
              "                                            max_cat_to_onehot=None,\n",
              "                                            max_delta_step=None, max_depth=None,\n",
              "                                            max_leaves=None,\n",
              "                                            min_child_weight=None, missing=nan,\n",
              "                                            monotone_constraints=None,\n",
              "                                            n_estimators=500, n_jobs=None,\n",
              "                                            nthread=-1, num_parallel_tree=None,\n",
              "                                            predictor=None, ...))"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultiOutputRegressor(estimator=XGBRegressor(base_score=None, booster=None,\n",
              "                                            callbacks=None,\n",
              "                                            colsample_bylevel=None,\n",
              "                                            colsample_bynode=None,\n",
              "                                            colsample_bytree=None,\n",
              "                                            early_stopping_rounds=None,\n",
              "                                            enable_categorical=False,\n",
              "                                            eval_metric=None,\n",
              "                                            feature_types=None, gamma=None,\n",
              "                                            gpu_id=None, grow_policy=None,\n",
              "                                            importance_type=None,\n",
              "                                            interaction_constraints=None,\n",
              "                                            learning_rate=0.1, max_bin=None,\n",
              "                                            max_cat_threshold=None,\n",
              "                                            max_cat_to_onehot=None,\n",
              "                                            max_delta_step=None, max_depth=None,\n",
              "                                            max_leaves=None,\n",
              "                                            min_child_weight=None, missing=nan,\n",
              "                                            monotone_constraints=None,\n",
              "                                            n_estimators=500, n_jobs=None,\n",
              "                                            nthread=-1, num_parallel_tree=None,\n",
              "                                            predictor=None, ...))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultiOutputRegressor</label><div class=\"sk-toggleable__content\"><pre>MultiOutputRegressor(estimator=XGBRegressor(base_score=None, booster=None,\n",
              "                                            callbacks=None,\n",
              "                                            colsample_bylevel=None,\n",
              "                                            colsample_bynode=None,\n",
              "                                            colsample_bytree=None,\n",
              "                                            early_stopping_rounds=None,\n",
              "                                            enable_categorical=False,\n",
              "                                            eval_metric=None,\n",
              "                                            feature_types=None, gamma=None,\n",
              "                                            gpu_id=None, grow_policy=None,\n",
              "                                            importance_type=None,\n",
              "                                            interaction_constraints=None,\n",
              "                                            learning_rate=0.1, max_bin=None,\n",
              "                                            max_cat_threshold=None,\n",
              "                                            max_cat_to_onehot=None,\n",
              "                                            max_delta_step=None, max_depth=None,\n",
              "                                            max_leaves=None,\n",
              "                                            min_child_weight=None, missing=nan,\n",
              "                                            monotone_constraints=None,\n",
              "                                            n_estimators=500, n_jobs=None,\n",
              "                                            nthread=-1, num_parallel_tree=None,\n",
              "                                            predictor=None, ...))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
              "             colsample_bylevel=None, colsample_bynode=None,\n",
              "             colsample_bytree=None, early_stopping_rounds=None,\n",
              "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
              "             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
              "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
              "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "             n_estimators=500, n_jobs=None, nthread=-1, num_parallel_tree=None,\n",
              "             predictor=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
              "             colsample_bylevel=None, colsample_bynode=None,\n",
              "             colsample_bytree=None, early_stopping_rounds=None,\n",
              "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
              "             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
              "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
              "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "             n_estimators=500, n_jobs=None, nthread=-1, num_parallel_tree=None,\n",
              "             predictor=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#RandomForest\n",
        "#my_model_1 = MultiOutputRegressor(RandomForestRegressor(n_estimators=500, criterion=\"squared_error\"))\n",
        "#my_model_1 = RandomForestRegressor(n_estimators=500, criterion=\"absolute_error\", bootstrap = True, oob_score = True, random_state = 3, verbose = 3, n_jobs=-1)\n",
        "my_model_1 = RandomForestRegressor(n_estimators=500, criterion=\"squared_error\", bootstrap = True, oob_score = True, random_state = 3, verbose = 3, n_jobs=-1)\n",
        "my_model_1.fit(x,y)"
      ],
      "metadata": {
        "id": "rG9LSozu2ND1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_1 = my_model_1.predict(x)\n",
        "mae_1 = mean_absolute_error(predictions_1,y)\n",
        "print(\"Mean Absolute Training Error:\" , mae_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJLRn68tERbG",
        "outputId": "1472dffc-d652-434b-ecdc-486001501f8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Training Error: 0.0005189102801443372\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For non converge prediction"
      ],
      "metadata": {
        "id": "zmdubWYsQB2M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = pd.read_csv(\"Real_non_converge.csv\")\n",
        "\n",
        "for i in range(1, 321):\n",
        "  df_test.iloc[:,i] = (df_test.iloc[:,i] - df_test.iloc[:,i].min()) / (df_test.iloc[:,i].max() - df_test.iloc[:,i].min())\n",
        "x_test = df_test.iloc[:,0:641].values\n",
        "#x_test = x_test.reshape(-1,1)\n",
        "\n",
        "for i in range(0,1):\n",
        "  bias_test = x_test[:,0]\n",
        "\n",
        "  bias_inv_test = np.reciprocal(bias_test)\n",
        "  bias_inv_test[bias_inv_test == inf] = 0\n",
        "\n",
        "  bias_0_5_test = np.power(bias_test,0.5)\n",
        "  bias_inv_0_5_test = np.power(bias_inv_test,0.5)\n",
        "\n",
        "  bias_2_test = np.power(bias_test,2)\n",
        "  bias_inv_2_test = np.power(bias_inv_test,2)\n",
        "\n",
        "  bias_3_test = np.power(bias_test,3)\n",
        "  bias_inv_3_test = np.power(bias_inv_test,3)\n",
        "\n",
        "  bias_log_test = np.log(bias_test)\n",
        "  bias_log_inv_test = np.reciprocal(bias_log_test)\n",
        "  bias_log_test [bias_log_test==-inf] = 0 \n",
        "\n",
        "  bias_neg_test = bias_test*(-1)\n",
        "  bias_exp_test = np.exp(bias_test)\n",
        "  bias_neg_exp_test = np.exp(bias_neg_test)\n",
        "\n",
        "  b = bias_inv_test.reshape(-1,1)\n",
        "  x_test = np.append(x_test,b,axis=1)\n",
        "\n",
        "  b = bias_0_5_test.reshape(-1,1)\n",
        "  x_test = np.append(x_test,b,axis=1)\n",
        "\n",
        "\n",
        "  b = bias_inv_0_5_test.reshape(-1,1)\n",
        "  x_test = np.append(x_test,b,axis=1)\n",
        "\n",
        "  b = bias_2_test.reshape(-1,1)\n",
        "  x_test = np.append(x_test,b,axis=1)\n",
        "\n",
        "  b = bias_inv_2_test.reshape(-1,1)\n",
        "  x_test = np.append(x_test,b,axis=1)\n",
        "\n",
        "  b = bias_3_test.reshape(-1,1)\n",
        "  x_test = np.append(x_test,b,axis=1)\n",
        "\n",
        "  b = bias_inv_3_test.reshape(-1,1)\n",
        "  x_test = np.append(x_test,b,axis=1)\n",
        "\n",
        "  b = bias_log_test.reshape(-1,1)\n",
        "  x_test = np.append(x_test,b,axis=1)\n",
        "\n",
        "  b = bias_log_inv_test.reshape(-1,1)\n",
        "  x_test = np.append(x_test,b,axis=1)\n",
        "\n",
        "  b = bias_exp_test.reshape(-1,1)\n",
        "  x_test = np.append(x_test,b,axis=1)\n",
        "\n",
        "  b = bias_neg_exp_test.reshape(-1,1)\n",
        "  x_test = np.append(x_test,b,axis=1)\n",
        "x_test.shape"
      ],
      "metadata": {
        "id": "3DhXL53E8nl3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dcc4cf3-3cc7-47f0-ee9a-37d172151912"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-f79cd4f2a7e0>:11: RuntimeWarning: divide by zero encountered in reciprocal\n",
            "  bias_inv_test = np.reciprocal(bias_test)\n",
            "<ipython-input-10-f79cd4f2a7e0>:23: RuntimeWarning: divide by zero encountered in log\n",
            "  bias_log_test = np.log(bias_test)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6, 652)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_test = my_model_1.predict(x_test)\n",
        "output_test"
      ],
      "metadata": {
        "id": "OtfViIZk-OjX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7955bd5a-6290-4fd7-966c-93f42019f73c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.24187005, 0.24191728, 0.24192815, ..., 0.24257383, 0.24257408,\n",
              "        0.24257404],\n",
              "       [0.24187005, 0.24191728, 0.24192815, ..., 0.24257383, 0.24257408,\n",
              "        0.24257404],\n",
              "       [0.43647593, 0.43657747, 0.43648407, ..., 0.04005232, 0.04005511,\n",
              "        0.04004386],\n",
              "       [0.43644515, 0.43653423, 0.4364406 , ..., 0.04005232, 0.04005511,\n",
              "        0.04004386],\n",
              "       [0.33639556, 0.33641928, 0.33641657, ..., 0.04002792, 0.04003098,\n",
              "        0.04003695],\n",
              "       [0.4496828 , 0.44974554, 0.44964585, ..., 0.15053132, 0.15052849,\n",
              "        0.15053764]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_guess = (-1)*output_test\n",
        "input_guess"
      ],
      "metadata": {
        "id": "mYW2Mwmz-e4M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "747d7f86-03c6-468b-990c-3dc46e62426b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.24187005, -0.24191728, -0.24192815, ..., -0.24257383,\n",
              "        -0.24257408, -0.24257404],\n",
              "       [-0.24187005, -0.24191728, -0.24192815, ..., -0.24257383,\n",
              "        -0.24257408, -0.24257404],\n",
              "       [-0.43647593, -0.43657747, -0.43648407, ..., -0.04005232,\n",
              "        -0.04005511, -0.04004386],\n",
              "       [-0.43644515, -0.43653423, -0.4364406 , ..., -0.04005232,\n",
              "        -0.04005511, -0.04004386],\n",
              "       [-0.33639556, -0.33641928, -0.33641657, ..., -0.04002792,\n",
              "        -0.04003098, -0.04003695],\n",
              "       [-0.4496828 , -0.44974554, -0.44964585, ..., -0.15053132,\n",
              "        -0.15052849, -0.15053764]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(input_guess)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1a9eg-pUL6WN",
        "outputId": "99a9d342-cb38-4e89-c344-ace3be72c746"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "U_guess = pd.DataFrame(input_guess)\n",
        "U_guess.to_csv('U_guess.csv')"
      ],
      "metadata": {
        "id": "9JnvpmL1MT1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "re.sub(r'\\s+', ';', '-0.449411885\t-0.449411884\t-0.449411883\t-0.449411881\t-0.449411879\t-0.449411876\t-0.449411873\t-0.449411869\t-0.449411865\t-0.449411859\t-0.449411853\t-0.449411711\t-0.44941143\t-0.44941101\t-0.449410449\t-0.449409743\t-0.449408888\t-0.449407881\t-0.449406716\t-0.449405386\t-0.449403884\t-0.449402202\t-0.449400331\t-0.449398261\t-0.449395982\t-0.44939348\t-0.449390741\t-0.449387753\t-0.449384497\t-0.449380958\t-0.449377115\t-0.449372949\t-0.449368436\t-0.449363553\t-0.449358272\t-0.449352567\t-0.449346406\t-0.449339755\t-0.449332581\t-0.449324842\t-0.449316499\t-0.449307506\t-0.449297815\t-0.449287373\t-0.449276126\t-0.449264011\t-0.449250965\t-0.449236917\t-0.449221791\t-0.449205506\t-0.449187976\t-0.449169105\t-0.449148792\t-0.449126929\t-0.449103397\t-0.449078071\t-0.449050814\t-0.449021481\t-0.448989913\t-0.448955941\t-0.448919384\t-0.448880045\t-0.448837712\t-0.448792159\t-0.448743143\t-0.448690399\t-0.448633645\t-0.448572578\t-0.44850687\t-0.448436169\t-0.448360098\t-0.448278248\t-0.448190182\t-0.44809543\t-0.447993484\t-0.4478838\t-0.447765793\t-0.447638833\t-0.447502243\t-0.447355294\t-0.447197203\t-0.44702713\t-0.44684417\t-0.44664735\t-0.446435625\t-0.446207872\t-0.445962885\t-0.445699365\t-0.44541592\t-0.445111054\t-0.444783159\t-0.444430508\t-0.444051247\t-0.443643388\t-0.443204793\t-0.44273317\t-0.442226059\t-0.441680824\t-0.441094634\t-0.440464456\t-0.439787039\t-0.439058901\t-0.438276309\t-0.437435271\t-0.439931512\t-0.43896046\t-0.437917225\t-0.436796585\t-0.44279296\t-0.441503891\t-0.440122948\t-0.43865638\t-0.471096548\t-0.46943541\t-0.464264559\t-0.462402881\t-0.471440508\t-0.4693673\t-0.459972838\t-0.457779017\t-0.458171628\t-0.455936662\t-0.419660439\t-0.417374239\t-0.418265697\t-0.415923739\t-0.402538294\t-0.400110457\t-0.410231746\t-0.407694356\t-0.402490943\t-0.399827302\t-0.394896488\t-0.392091695\t-0.386006178\t-0.383084792\t-0.3919206\t-0.388906794\t-0.373236696\t-0.370136994\t-0.356801762\t-0.353625521\t-0.35260319\t-0.3494054\t-0.300028197\t-0.296868142\t-0.281922287\t-0.278788238\t-0.266864343\t-0.263749579\t-0.270843408\t-0.267745627\t-0.248056315\t-0.244975724\t-0.288104229\t-0.285042065\t-0.291789555\t-0.28874686\t-0.294513993\t-0.291490815\t-0.326477023\t-0.323472177\t-0.337075772\t-0.334087219\t-0.341305883\t-0.338331032\t-0.325561895\t-0.322597796\t-0.342238077\t-0.339282196\t-0.298329754\t-0.295380767\t-0.301235239\t-0.298293389\t-0.285155611\t-0.282222469\t-0.287494553\t-0.284572467\t-0.259056776\t-0.25614808\t-0.253446894\t-0.250553777\t-0.238869346\t-0.235994371\t-0.215329838\t-0.212477044\t-0.201437645\t-0.198613755\t-0.188008035\t-0.185223823\t-0.182265277\t-0.179537564\t-0.164247108\t-0.161601913\t-0.176811988\t-0.174289845\t-0.168648801\t-0.166302844\t-0.171866641\t-0.169687315\t-0.164971684\t-0.162927616\t-0.17356421\t-0.17166218\t-0.158828837\t-0.157072005\t-0.158600009\t-0.156971973\t-0.121391528\t-0.119863196\t-0.120992489\t-0.119573387\t-0.111012381\t-0.109713853\t-0.119487646\t-0.118335773\t-0.11387127\t-0.112909407\t-0.146068193\t-0.145324479\t-0.144695592\t-0.144199217\t-0.151053144\t-0.150739916\t-0.150462651\t-0.150224701\t-0.153429617\t-0.153252776\t-0.153094953\t-0.152956965\t-0.152839629\t-0.152730474\t-0.152628927\t-0.152534458\t-0.152446572\t-0.152364809\t-0.152288744\t-0.152217977\t-0.152152141\t-0.15209089\t-0.152033905\t-0.15198089\t-0.151931567\t-0.151885679\t-0.151842987\t-0.151803269\t-0.151766316\t-0.151731937\t-0.151699952\t-0.151670195\t-0.15164251\t-0.151616753\t-0.15159279\t-0.151570496\t-0.151549755\t-0.151530458\t-0.151512506\t-0.151495803\t-0.151480264\t-0.151465808\t-0.151452359\t-0.151439846\t-0.151428206\t-0.151417376\t-0.151407301\t-0.151397928\t-0.151389208\t-0.151381095\t-0.151373548\t-0.151366527\t-0.151359995\t-0.151353918\t-0.151348265\t-0.151343007\t-0.151338114\t-0.151333564\t-0.15132933\t-0.151325391\t-0.151321728\t-0.15131832\t-0.15131515\t-0.151312201\t-0.151309458\t-0.151306907\t-0.151304534\t-0.151302327\t-0.151300274\t-0.151298364\t-0.151296589\t-0.151294937\t-0.151293402\t-0.151291974\t-0.151290647\t-0.151289413\t-0.151288265\t-0.151287199\t-0.151286208\t-0.151285287\t-0.151284431\t-0.151283636\t-0.151282898\t-0.151282213\t-0.151281577\t-0.151280987\t-0.15128044\t-0.151279932\t-0.151279463\t-0.151279027\t-0.151278625\t-0.151278253\t-0.15127791\t-0.151277594\t-0.151277302\t-0.151277034\t-0.151276788\t-0.151276563\t-0.151276358\t-0.151276172\t-0.151276003\t-0.151276003')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "id": "pcSH060wMz27",
        "outputId": "ea475183-a006-4717-a421-fba11d594c41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'-0.449411885;-0.449411884;-0.449411883;-0.449411881;-0.449411879;-0.449411876;-0.449411873;-0.449411869;-0.449411865;-0.449411859;-0.449411853;-0.449411711;-0.44941143;-0.44941101;-0.449410449;-0.449409743;-0.449408888;-0.449407881;-0.449406716;-0.449405386;-0.449403884;-0.449402202;-0.449400331;-0.449398261;-0.449395982;-0.44939348;-0.449390741;-0.449387753;-0.449384497;-0.449380958;-0.449377115;-0.449372949;-0.449368436;-0.449363553;-0.449358272;-0.449352567;-0.449346406;-0.449339755;-0.449332581;-0.449324842;-0.449316499;-0.449307506;-0.449297815;-0.449287373;-0.449276126;-0.449264011;-0.449250965;-0.449236917;-0.449221791;-0.449205506;-0.449187976;-0.449169105;-0.449148792;-0.449126929;-0.449103397;-0.449078071;-0.449050814;-0.449021481;-0.448989913;-0.448955941;-0.448919384;-0.448880045;-0.448837712;-0.448792159;-0.448743143;-0.448690399;-0.448633645;-0.448572578;-0.44850687;-0.448436169;-0.448360098;-0.448278248;-0.448190182;-0.44809543;-0.447993484;-0.4478838;-0.447765793;-0.447638833;-0.447502243;-0.447355294;-0.447197203;-0.44702713;-0.44684417;-0.44664735;-0.446435625;-0.446207872;-0.445962885;-0.445699365;-0.44541592;-0.445111054;-0.444783159;-0.444430508;-0.444051247;-0.443643388;-0.443204793;-0.44273317;-0.442226059;-0.441680824;-0.441094634;-0.440464456;-0.439787039;-0.439058901;-0.438276309;-0.437435271;-0.439931512;-0.43896046;-0.437917225;-0.436796585;-0.44279296;-0.441503891;-0.440122948;-0.43865638;-0.471096548;-0.46943541;-0.464264559;-0.462402881;-0.471440508;-0.4693673;-0.459972838;-0.457779017;-0.458171628;-0.455936662;-0.419660439;-0.417374239;-0.418265697;-0.415923739;-0.402538294;-0.400110457;-0.410231746;-0.407694356;-0.402490943;-0.399827302;-0.394896488;-0.392091695;-0.386006178;-0.383084792;-0.3919206;-0.388906794;-0.373236696;-0.370136994;-0.356801762;-0.353625521;-0.35260319;-0.3494054;-0.300028197;-0.296868142;-0.281922287;-0.278788238;-0.266864343;-0.263749579;-0.270843408;-0.267745627;-0.248056315;-0.244975724;-0.288104229;-0.285042065;-0.291789555;-0.28874686;-0.294513993;-0.291490815;-0.326477023;-0.323472177;-0.337075772;-0.334087219;-0.341305883;-0.338331032;-0.325561895;-0.322597796;-0.342238077;-0.339282196;-0.298329754;-0.295380767;-0.301235239;-0.298293389;-0.285155611;-0.282222469;-0.287494553;-0.284572467;-0.259056776;-0.25614808;-0.253446894;-0.250553777;-0.238869346;-0.235994371;-0.215329838;-0.212477044;-0.201437645;-0.198613755;-0.188008035;-0.185223823;-0.182265277;-0.179537564;-0.164247108;-0.161601913;-0.176811988;-0.174289845;-0.168648801;-0.166302844;-0.171866641;-0.169687315;-0.164971684;-0.162927616;-0.17356421;-0.17166218;-0.158828837;-0.157072005;-0.158600009;-0.156971973;-0.121391528;-0.119863196;-0.120992489;-0.119573387;-0.111012381;-0.109713853;-0.119487646;-0.118335773;-0.11387127;-0.112909407;-0.146068193;-0.145324479;-0.144695592;-0.144199217;-0.151053144;-0.150739916;-0.150462651;-0.150224701;-0.153429617;-0.153252776;-0.153094953;-0.152956965;-0.152839629;-0.152730474;-0.152628927;-0.152534458;-0.152446572;-0.152364809;-0.152288744;-0.152217977;-0.152152141;-0.15209089;-0.152033905;-0.15198089;-0.151931567;-0.151885679;-0.151842987;-0.151803269;-0.151766316;-0.151731937;-0.151699952;-0.151670195;-0.15164251;-0.151616753;-0.15159279;-0.151570496;-0.151549755;-0.151530458;-0.151512506;-0.151495803;-0.151480264;-0.151465808;-0.151452359;-0.151439846;-0.151428206;-0.151417376;-0.151407301;-0.151397928;-0.151389208;-0.151381095;-0.151373548;-0.151366527;-0.151359995;-0.151353918;-0.151348265;-0.151343007;-0.151338114;-0.151333564;-0.15132933;-0.151325391;-0.151321728;-0.15131832;-0.15131515;-0.151312201;-0.151309458;-0.151306907;-0.151304534;-0.151302327;-0.151300274;-0.151298364;-0.151296589;-0.151294937;-0.151293402;-0.151291974;-0.151290647;-0.151289413;-0.151288265;-0.151287199;-0.151286208;-0.151285287;-0.151284431;-0.151283636;-0.151282898;-0.151282213;-0.151281577;-0.151280987;-0.15128044;-0.151279932;-0.151279463;-0.151279027;-0.151278625;-0.151278253;-0.15127791;-0.151277594;-0.151277302;-0.151277034;-0.151276788;-0.151276563;-0.151276358;-0.151276172;-0.151276003;-0.151276003'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For model testing"
      ],
      "metadata": {
        "id": "KM1f7BfwQIQ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# df_test = pd.read_csv(\"Real_Test.csv\")\n",
        "\n",
        "# for i in range(1, 321):\n",
        "#   df_test.iloc[:,i] = (df_test.iloc[:,i] - df_test.iloc[:,i].min()) / (df_test.iloc[:,i].max() - df_test.iloc[:,i].min())\n",
        "# x_test = df_test.iloc[:,0:641].values\n",
        "# #x_test = x_test.reshape(-1,1)\n",
        "\n",
        "# for i in range(0,1):\n",
        "#   bias_test = x_test[:,0]\n",
        "\n",
        "#   bias_inv_test = np.reciprocal(bias_test)\n",
        "#   bias_inv_test[bias_inv_test == inf] = 0\n",
        "\n",
        "#   bias_0_5_test = np.power(bias_test,0.5)\n",
        "#   bias_inv_0_5_test = np.power(bias_inv_test,0.5)\n",
        "\n",
        "#   bias_2_test = np.power(bias_test,2)\n",
        "#   bias_inv_2_test = np.power(bias_inv_test,2)\n",
        "\n",
        "#   bias_3_test = np.power(bias_test,3)\n",
        "#   bias_inv_3_test = np.power(bias_inv_test,3)\n",
        "\n",
        "#   bias_log_test = np.log(bias_test)\n",
        "#   bias_log_inv_test = np.reciprocal(bias_log_test)\n",
        "#   bias_log_test [bias_log_test==-inf] = 0 \n",
        "\n",
        "#   bias_neg_test = bias_test*(-1)\n",
        "#   bias_exp_test = np.exp(bias_test)\n",
        "#   bias_neg_exp_test = np.exp(bias_neg_test)\n",
        "\n",
        "#   b = bias_inv_test.reshape(-1,1)\n",
        "#   x_test = np.append(x_test,b,axis=1)\n",
        "\n",
        "#   b = bias_0_5_test.reshape(-1,1)\n",
        "#   x_test = np.append(x_test,b,axis=1)\n",
        "\n",
        "\n",
        "#   b = bias_inv_0_5_test.reshape(-1,1)\n",
        "#   x_test = np.append(x_test,b,axis=1)\n",
        "\n",
        "#   b = bias_2_test.reshape(-1,1)\n",
        "#   x_test = np.append(x_test,b,axis=1)\n",
        "\n",
        "#   b = bias_inv_2_test.reshape(-1,1)\n",
        "#   x_test = np.append(x_test,b,axis=1)\n",
        "\n",
        "#   b = bias_3_test.reshape(-1,1)\n",
        "#   x_test = np.append(x_test,b,axis=1)\n",
        "\n",
        "#   b = bias_inv_3_test.reshape(-1,1)\n",
        "#   x_test = np.append(x_test,b,axis=1)\n",
        "\n",
        "#   b = bias_log_test.reshape(-1,1)\n",
        "#   x_test = np.append(x_test,b,axis=1)\n",
        "\n",
        "#   b = bias_log_inv_test.reshape(-1,1)\n",
        "#   x_test = np.append(x_test,b,axis=1)\n",
        "\n",
        "#   b = bias_exp_test.reshape(-1,1)\n",
        "#   x_test = np.append(x_test,b,axis=1)\n",
        "\n",
        "#   b = bias_neg_exp_test.reshape(-1,1)\n",
        "#   x_test = np.append(x_test,b,axis=1)\n",
        "# x_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9gU9oZ_D-4v",
        "outputId": "2423c2ce-36ca-455c-c7b7-ab556b2a3e59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in reciprocal\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: RuntimeWarning: divide by zero encountered in log\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50, 652)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# output_test = my_model_1.predict(x_test)\n",
        "# y_test = df_test.iloc[:,961:1281].values\n",
        "# mae_2 = mean_absolute_error(output_test,y_test)\n",
        "# print(\"Mean Absolute Testing Error:\" , mae_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrbpKuEojCxG",
        "outputId": "ef7d6e99-3a97-453b-b381-693ba42db533"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 124 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 284 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done 500 out of 500 | elapsed:    0.2s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Testing Error: 0.011516999681853119\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_flat = df_test.iloc[:,321:641].values\n",
        "x_output = x_flat - output_test\n",
        "PP = df_test.iloc[:,641:961].values\n",
        "\n",
        "\n",
        "plt.figure()\n",
        "for i in range(0, 50):\n",
        "  plt.plot(x_output[i])\n",
        "  plt.plot(PP[i])\n",
        "  plt.xlabel(\"Samples from contact metal\")\n",
        "  plt.ylabel(\"Potential\")\n",
        "  plt.savefig(\"images/output_\"+str(i))\n",
        "  plt.clf()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "8iGCm5BiE2PY",
        "outputId": "ce4a5166-af96-4c4e-bf22-2c706e86a077"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#To download zip\n",
        "!zip -r /content/images.zip /content/images\n",
        "files.download(\"/content/images.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 943
        },
        "id": "dEozhk6aIXzF",
        "outputId": "69278abc-6403-489e-eb6d-64128d9a97f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/images/ (stored 0%)\n",
            "  adding: content/images/output_37.png (deflated 5%)\n",
            "  adding: content/images/output_24.png (deflated 4%)\n",
            "  adding: content/images/output_4.png (deflated 4%)\n",
            "  adding: content/images/output_1.png (deflated 4%)\n",
            "  adding: content/images/output_16.png (deflated 5%)\n",
            "  adding: content/images/output_43.png (deflated 4%)\n",
            "  adding: content/images/output_23.png (deflated 4%)\n",
            "  adding: content/images/output_3.png (deflated 5%)\n",
            "  adding: content/images/output_11.png (deflated 4%)\n",
            "  adding: content/images/output_0.png (deflated 3%)\n",
            "  adding: content/images/output_34.png (deflated 7%)\n",
            "  adding: content/images/output_15.png (deflated 4%)\n",
            "  adding: content/images/output_49.png (deflated 7%)\n",
            "  adding: content/images/output_28.png (deflated 5%)\n",
            "  adding: content/images/output_22.png (deflated 4%)\n",
            "  adding: content/images/output_41.png (deflated 4%)\n",
            "  adding: content/images/output_35.png (deflated 7%)\n",
            "  adding: content/images/output_32.png (deflated 7%)\n",
            "  adding: content/images/output_9.png (deflated 4%)\n",
            "  adding: content/images/output_25.png (deflated 4%)\n",
            "  adding: content/images/output_12.png (deflated 4%)\n",
            "  adding: content/images/output_26.png (deflated 5%)\n",
            "  adding: content/images/output_36.png (deflated 5%)\n",
            "  adding: content/images/output_14.png (deflated 4%)\n",
            "  adding: content/images/output_38.png (deflated 4%)\n",
            "  adding: content/images/output_29.png (deflated 5%)\n",
            "  adding: content/images/output_46.png (deflated 6%)\n",
            "  adding: content/images/output_7.png (deflated 5%)\n",
            "  adding: content/images/output_45.png (deflated 6%)\n",
            "  adding: content/images/output_47.png (deflated 6%)\n",
            "  adding: content/images/output_21.png (deflated 4%)\n",
            "  adding: content/images/output_44.png (deflated 4%)\n",
            "  adding: content/images/output_39.png (deflated 4%)\n",
            "  adding: content/images/output_2.png (deflated 4%)\n",
            "  adding: content/images/output_10.png (deflated 5%)\n",
            "  adding: content/images/output_48.png (deflated 7%)\n",
            "  adding: content/images/output_20.png (deflated 4%)\n",
            "  adding: content/images/output_40.png (deflated 4%)\n",
            "  adding: content/images/output_17.png (deflated 5%)\n",
            "  adding: content/images/output_31.png (deflated 7%)\n",
            "  adding: content/images/output_27.png (deflated 5%)\n",
            "  adding: content/images/output_8.png (deflated 5%)\n",
            "  adding: content/images/output_42.png (deflated 4%)\n",
            "  adding: content/images/output_30.png (deflated 4%)\n",
            "  adding: content/images/output_33.png (deflated 6%)\n",
            "  adding: content/images/output_18.png (deflated 5%)\n",
            "  adding: content/images/output_13.png (deflated 4%)\n",
            "  adding: content/images/output_19.png (deflated 5%)\n",
            "  adding: content/images/output_5.png (deflated 4%)\n",
            "  adding: content/images/output_6.png (deflated 4%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_6226ab55-f8c2-44e8-84aa-7af9cb1fe610\", \"images.zip\", 847925)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0HKlwpX0L17-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}